# MTL-LoRA-finetuning
LM fine-tuning using Lora and MTL-Lora for a medical chatbot
This project aims to develop a medical assistant by fine-tuning the LLaMA 1b model (1 billion parameters).

The project is divided into two main phases:

Phase 1: Fine-Tuning with PubMedQA Dataset
We will fine-tune the LLaMA model using the PubMedQA dataset, which includes medical questions, context and answers. This phase focuses on enhancing the model's lexicon and semantic understanding in the medical domain. The results of two fine-tuning techniques will be compared:

LoRA (Low-Rank Adaptation):

LoRA adds low-rank adaptation matrices to the frozen weights of the model.
This technique enables efficient fine-tuning by training only a few additional parameters.
Traditional Fine-Tuning:

All layers of the model are frozen except for the final head.
Gradients are allowed to flow only through the last layer during training.
Evaluation
The performance of the three configurations (1) base model, (2) LoRA-tuned model, and (3) traditionally fine-tuned modelâ€”will be compared. Evaluation metrics will include:

Perplexity
BLEU Score
ROUGE Score
Additionally, chatbot outputs generated by the three models will be compared to assess qualitative differences.

Phase 2: Exploring Multi-Task LoRA
In this phase, we will explore advanced LoRA techniques to enable the model to perform multiple tasks learned through a single fine-tuning process.

Approach
We aim to implement and test a theoretical LoRA framework introduced in October 2024 (reference link). This framework proposes leveraging LoRA's adaptation capabilities for multi-task learning.

The goal is to train the model efficiently on various tasks simultaneously while maintaining high performance across all tasks.
